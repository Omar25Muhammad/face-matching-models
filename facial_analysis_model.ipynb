{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d68255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil  # To handle file removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871c3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"image_face_test/two_faces/*.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09a817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\n",
    "    \"yolov8_model/yolov8n-face.pt\"\n",
    ")  # load a pretrained YOLOv8n detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4efbe680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/2 d:\\face-matching-models\\image_face_test\\two_faces\\moad.jpg: 384x640 1 face, 280.7ms\n",
      "image 2/2 d:\\face-matching-models\\image_face_test\\two_faces\\moad_pass (1).jpg: 640x448 1 face, 277.5ms\n",
      "Speed: 13.3ms preprocess, 279.1ms inference, 15.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1md:\\face-matching-models\\runs\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"runs\"):\n",
    "    shutil.rmtree(\"runs\")\n",
    "results = model(source, save_crop=True)\n",
    "# results.save_crop('image_face_test/two_faces/cropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc20ca",
   "metadata": {},
   "source": [
    "### Extract Face Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175edc3",
   "metadata": {},
   "source": [
    "#### 1. Get the cropped faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d5c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db210262",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cropped_faces_dir = r\"runs\\detect\\predict\\crops\\face\"\n",
    "# This folder was created by YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62b961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs\\detect\\predict\\crops\\face\\moad.jpg\n",
      "runs\\detect\\predict\\crops\\face\\moad_pass (1).jpg\n"
     ]
    }
   ],
   "source": [
    "faces_images = glob.glob(os.path.join(target_cropped_faces_dir, \"*.jpg\"))\n",
    "\n",
    "# Loop through the list of image files\n",
    "for image_file in faces_images:\n",
    "    print(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d71519",
   "metadata": {},
   "source": [
    "#### 2. Extract Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5feb658",
   "metadata": {},
   "source": [
    "DeepFace library version 0.0.80 is used to do so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d24748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepface==0.0.80 in .\\.venv\\lib\\site-packages (0.0.80)\n",
      "Requirement already satisfied: numpy>=1.14.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.23.4 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (2.2.0)\n",
      "Requirement already satisfied: gdown>=3.10.1 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (5.1.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (4.66.1)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (10.2.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (4.9.0.80)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (2.15.0)\n",
      "Requirement already satisfied: keras>=2.2.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (2.15.0)\n",
      "Requirement already satisfied: Flask>=1.1.2 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (3.0.2)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (0.1.1)\n",
      "Requirement already satisfied: retina-face>=0.0.1 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (0.0.14)\n",
      "Requirement already satisfied: fire>=0.4.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (0.5.0)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (21.2.0)\n",
      "Requirement already satisfied: Deprecated>=1.2.13 in .\\.venv\\lib\\site-packages (from deepface==0.0.80) (1.2.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in .\\.venv\\lib\\site-packages (from Deprecated>=1.2.13->deepface==0.0.80) (1.14.1)\n",
      "Requirement already satisfied: six in .\\.venv\\lib\\site-packages (from fire>=0.4.0->deepface==0.0.80) (1.16.0)\n",
      "Requirement already satisfied: termcolor in .\\.venv\\lib\\site-packages (from fire>=0.4.0->deepface==0.0.80) (2.4.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in .\\.venv\\lib\\site-packages (from Flask>=1.1.2->deepface==0.0.80) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in .\\.venv\\lib\\site-packages (from Flask>=1.1.2->deepface==0.0.80) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in .\\.venv\\lib\\site-packages (from Flask>=1.1.2->deepface==0.0.80) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in .\\.venv\\lib\\site-packages (from Flask>=1.1.2->deepface==0.0.80) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in .\\.venv\\lib\\site-packages (from Flask>=1.1.2->deepface==0.0.80) (1.7.0)\n",
      "Requirement already satisfied: beautifulsoup4 in .\\.venv\\lib\\site-packages (from gdown>=3.10.1->deepface==0.0.80) (4.12.3)\n",
      "Requirement already satisfied: filelock in .\\.venv\\lib\\site-packages (from gdown>=3.10.1->deepface==0.0.80) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in .\\.venv\\lib\\site-packages (from gdown>=3.10.1->deepface==0.0.80) (2.31.0)\n",
      "Requirement already satisfied: packaging in .\\.venv\\lib\\site-packages (from gunicorn>=20.1.0->deepface==0.0.80) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\lib\\site-packages (from pandas>=0.23.4->deepface==0.0.80) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\.venv\\lib\\site-packages (from pandas>=0.23.4->deepface==0.0.80) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\.venv\\lib\\site-packages (from pandas>=0.23.4->deepface==0.0.80) (2023.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in .\\.venv\\lib\\site-packages (from tensorflow>=1.9.0->deepface==0.0.80) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (4.25.2)\n",
      "Requirement already satisfied: setuptools in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (4.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in .\\.venv\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (2.15.0)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm>=4.30.0->deepface==0.0.80) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface==0.0.80) (2.1.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\.venv\\lib\\site-packages (from beautifulsoup4->gdown>=3.10.1->deepface==0.0.80) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.80) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.80) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.80) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.80) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in .\\.venv\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.80) (1.7.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in .\\.venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in .\\.venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in .\\.venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in .\\.venv\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in .\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in .\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in .\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in .\\.venv\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in .\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in .\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow>=1.9.0->deepface==0.0.80) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install deepface==0.0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305c7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface.commons import distance as dst\n",
    "from deepface.DeepFace import represent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a13fa8",
   "metadata": {},
   "source": [
    "##### 2.1 Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6630e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_name = \"VGG-Face\"\n",
    "distance_metric = \"\"\n",
    "detector_backend = \"opencv\"\n",
    "align = True\n",
    "normalization = \"base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3137c5d",
   "metadata": {},
   "source": [
    "_This is from deepface v0.0.80 source code:_\n",
    "\n",
    "def findThreshold(model_name, distance_metric):\n",
    "\n",
    "    base_threshold = {\"cosine\": 0.40, \"euclidean\": 0.55, \"euclidean_l2\": 0.75}\n",
    "\n",
    "    thresholds = {\n",
    "        \"VGG-Face\": {\"cosine\": 0.40, \"euclidean\": 0.60, \"euclidean_l2\": 0.86},\n",
    "        \"Facenet\": {\"cosine\": 0.40, \"euclidean\": 10, \"euclidean_l2\": 0.80},\n",
    "        \"Facenet512\": {\"cosine\": 0.30, \"euclidean\": 23.56, \"euclidean_l2\": 1.04},\n",
    "        \"ArcFace\": {\"cosine\": 0.68, \"euclidean\": 4.15, \"euclidean_l2\": 1.13},\n",
    "        \"Dlib\": {\"cosine\": 0.07, \"euclidean\": 0.6, \"euclidean_l2\": 0.4},\n",
    "        \"SFace\": {\"cosine\": 0.593, \"euclidean\": 10.734, \"euclidean_l2\": 1.055},\n",
    "        \"OpenFace\": {\"cosine\": 0.10, \"euclidean\": 0.55, \"euclidean_l2\": 0.55},\n",
    "        \"DeepFace\": {\"cosine\": 0.23, \"euclidean\": 64, \"euclidean_l2\": 0.64},\n",
    "        \"DeepID\": {\"cosine\": 0.015, \"euclidean\": 45, \"euclidean_l2\": 0.17},\n",
    "    }\n",
    "\n",
    "    threshold = thresholds.get(model_name, base_threshold).get(distance_metric, 0.4)\n",
    "\n",
    "    return threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ceed6",
   "metadata": {},
   "source": [
    "_This is the docstring of represent function:_\n",
    "\n",
    "\"\"\"\n",
    "This function represents facial images as vectors. The function uses convolutional neural\n",
    "networks models to generate vector embeddings.\n",
    "\n",
    "    Parameters:\n",
    "            img_path (string): exact image path. Alternatively, numpy array (BGR) or based64\n",
    "            encoded images could be passed. Source image can have many faces. Then, result will\n",
    "            be the size of number of faces appearing in the source image.\n",
    "\n",
    "            model_name (string): VGG-Face, Facenet, Facenet512, OpenFace, DeepFace, DeepID, Dlib,\n",
    "            ArcFace, SFace\n",
    "\n",
    "            enforce_detection (boolean): If no face could not be detected in an image, then this\n",
    "            function will return exception by default. Set this to False not to have this exception.\n",
    "            This might be convenient for low resolution images.\n",
    "\n",
    "            detector_backend (string): set face detector backend to opencv, retinaface, mtcnn, ssd,\n",
    "            dlib, mediapipe or yolov8.\n",
    "\n",
    "            align (boolean): alignment according to the eye positions.\n",
    "\n",
    "            normalization (string): normalize the input image before feeding to model\n",
    "\n",
    "    Returns:\n",
    "            Represent function returns a list of object with multidimensional vector (embedding).\n",
    "            The number of dimensions is changing based on the reference model.\n",
    "            E.g. FaceNet returns 128 dimensional vector; VGG-Face returns 2622 dimensional vector.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4fdd9",
   "metadata": {},
   "source": [
    "##### 2.2 Represent Faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed7c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_images = glob.glob(os.path.join(target_cropped_faces_dir, \"*.jpg\"))\n",
    "\n",
    "# Loop through the list of image files\n",
    "for image_file in faces_images:\n",
    "    face_1_representation = represent(\n",
    "        img_path=image_file,\n",
    "        model_name=mode_name,\n",
    "        enforce_detection=False,\n",
    "        detector_backend=detector_backend,\n",
    "        align=align,\n",
    "        normalization=normalization,\n",
    "    )\n",
    "\n",
    "    face_2_representation = represent(\n",
    "        img_path=image_file,\n",
    "        model_name=mode_name,\n",
    "        enforce_detection=False,\n",
    "        detector_backend=detector_backend,\n",
    "        align=align,\n",
    "        normalization=normalization,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
